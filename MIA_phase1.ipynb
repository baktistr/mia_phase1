{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fd2d0f",
   "metadata": {},
   "source": [
    "## MIA FOR Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a92386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block to download the content if you use colab\n",
    "repo_url = \"https://github.com/2020pyfcrawl/Project_phase1.git\"\n",
    "\n",
    "import os, subprocess\n",
    "workdir = \"/content\"\n",
    "subprocess.run([\"git\", \"clone\", repo_url], check=True, cwd=workdir)\n",
    "print(\"Cloned into:\", os.listdir(workdir))\n",
    "\n",
    "% cd /content/Project_phase1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c559787",
   "metadata": {},
   "source": [
    "### Variables and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a53cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required libraries if you have not done so (on you local machine or GPU server)\n",
    "# you may not need to run this if you use colab as they are pre-installed, but you can always do it.\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dab5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, argparse\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_TORCHVISION\", \"1\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc as _auc\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable, check the current position to adjust the path\n",
    "target_model_dir = \"./models/gpt2_phase1\"\n",
    "data_dir = \"./data/wiki_json\"\n",
    "batch_size = 25\n",
    "\n",
    "# you may change block size if you like (max length for the tokenizer below)\n",
    "block_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef38029",
   "metadata": {},
   "source": [
    "### Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(ds, tok, max_len):\n",
    "    ds = ds.filter(lambda ex: ex.get(\"text\", None) and len(ex[\"text\"].strip()) > 0)\n",
    "\n",
    "    def _map(ex):\n",
    "        out = tok(ex[\"text\"], truncation=True, padding=True, max_length=max_len, return_attention_mask=True)\n",
    "        out[\"labels\"] = out[\"input_ids\"].copy()\n",
    "        return out\n",
    "\n",
    "    ds = ds.map(_map, batched=True, remove_columns=ds.column_names)\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]) \n",
    "    return ds\n",
    "\n",
    "def _read_json(path: Path):\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tests, you may only load a part of the data to save time while implementing, \n",
    "# as running all 2000 samples on CPU may be slow, but not a problem here for GPU\n",
    "\n",
    "# load test data\n",
    "data_dir = Path(data_dir)\n",
    "test_path = data_dir / \"test.json\"\n",
    "test_items = _read_json(test_path)  \n",
    "ds_test = Dataset.from_dict({\"text\": test_items})\n",
    "\n",
    "# tokenizer the test data\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_dir, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side=\"right\"\n",
    "\n",
    "ds_test = tokenize_dataset(ds_test, tokenizer, block_size)\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# you may load the model using the code:\n",
    "# model = AutoModelForCausalLM.from_pretrained(target_model_dir, dtype=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c1fef",
   "metadata": {},
   "source": [
    "### MIA\n",
    "\n",
    "Implement your attack here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8875cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement your attack here\n",
    "@torch.no_grad()\n",
    "def your_attack(\n",
    "\n",
    "):\n",
    "    pass\n",
    "\n",
    "scores_test = your_attack(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe128e",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label here to compute the performance, you will only have full access to the label in phase 1 as a warm-up\n",
    "label_path = data_dir / \"test_label.json\"\n",
    "label_items = _read_json(label_path)\n",
    "\n",
    "y_true = np.array(label_items)\n",
    "scores = np.array(scores_test)\n",
    "fpr, tpr, thr = roc_curve(y_true, scores)\n",
    "auc_val = roc_auc_score(y_true, scores)\n",
    "print(auc_val) # area under curve\n",
    "\n",
    "# some tpr fpr\n",
    "print(max(tpr[fpr < 0.01])) # TPR @ 0.01FPR\n",
    "print(max(tpr[fpr < 0.05])) # TPR @ 0.05FPR\n",
    "# report this three metrics in your report!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw ROC curve and attach the figure in the report\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_val:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance line')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title(f'MIA ROC Curve for Train Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
